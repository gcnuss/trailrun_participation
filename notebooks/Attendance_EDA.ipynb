{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import from python modules:\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('../data/cleaned_df_24NOV17.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New DF with Event Count and Repeat Data for each Person ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person_event_count_df = df.groupby(by='PersonID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 11669, 11670, 11671])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='PersonID').count().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='PersonID').count()['EventID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_attendees_df = pd.DataFrame.from_dict({'PersonID': person_event_count_df.index.values, \n",
    "                                              'Event_Count': person_event_count_df['EventID'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Count</th>\n",
       "      <th>PersonID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event_Count  PersonID\n",
       "0            1         1\n",
       "1            2         2\n",
       "2            1         3\n",
       "3            1         4\n",
       "4            2         5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_attendees_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull and Format Data from Baseline DF to Add to New Repeat Attendees DF\n",
    "\n",
    "* Event IDs\n",
    "* Event Dates\n",
    "* Series IDs\n",
    "* Calculate lag time between first and second events for those who have attended more than one event ('Repeat Lag Time')\n",
    "* ID whether a person is one off, repeat within a single series, or repeat across multiple series ('Cross_Series_Attend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "personID_eventID_dict = defaultdict(list)\n",
    "personID_eventdate_dict = defaultdict(list)\n",
    "personID_seriesID_dict = defaultdict(list)\n",
    "\n",
    "for num in person_event_count_df.index.values:\n",
    "    personID_eventID_dict[num].append(list(df[df['PersonID']==num]['EventID'].values))\n",
    "    personID_eventdate_dict[num].append(list(df[df['PersonID']==num]['Event_Date'].values))\n",
    "    personID_seriesID_dict[num].append(list(df[df['PersonID']==num]['SeriesID'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_attendees_df['Event_IDs'] = repeat_attendees_df['PersonID'].map(personID_eventID_dict).apply(lambda x: x[0])\n",
    "repeat_attendees_df['Event_Dates'] = repeat_attendees_df['PersonID'].map(personID_eventdate_dict).apply(lambda x: x[0])\n",
    "repeat_attendees_df['Series_IDs'] = repeat_attendees_df['PersonID'].map(personID_seriesID_dict).apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_trunc(date_list):\n",
    "    return [np.datetime64(item, 'D') for item in date_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_attendees_df['Event_Dates'] = repeat_attendees_df['Event_Dates'].apply(lambda x: date_trunc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repeat_lag_time(person_ID, duration_days=183):\n",
    "    if person_ID in repeat_attendees_df['PersonID'].values:\n",
    "        date_list = sorted(repeat_attendees_df[repeat_attendees_df['PersonID'] == person_ID]['Event_Dates'].values[0])\n",
    "        if len(date_list) == 1:\n",
    "            return 'One Off'\n",
    "        elif len(date_list) > 1:\n",
    "            first_event, second_event = heapq.nsmallest(2, date_list)\n",
    "            delta = second_event - first_event\n",
    "            if delta < np.timedelta64(duration_days, 'D'):\n",
    "                return 'Under {} days'.format(duration_days)\n",
    "            else:\n",
    "                return 'Over {} days'.format(duration_days)\n",
    "    else:\n",
    "        print 'Provided PersonID does not exist in the dataframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_attendees_df['Repeat_Lag_Time'] = repeat_attendees_df['PersonID'].apply(lambda x: repeat_lag_time(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_attendees_df['Cross_Series_Attend'] = repeat_attendees_df['Series_IDs'].apply(lambda x: \n",
    "                                            'One Off' if len(x) == 1 else\n",
    "                                            ('Single - {}'.format(x[0]) if len(set(x)) == 1 else 'Multiple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Count</th>\n",
       "      <th>PersonID</th>\n",
       "      <th>Event_IDs</th>\n",
       "      <th>Event_Dates</th>\n",
       "      <th>Series_IDs</th>\n",
       "      <th>Repeat_Lag_Time</th>\n",
       "      <th>Cross_Series_Attend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[2015-02-15]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>One Off</td>\n",
       "      <td>One Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 17]</td>\n",
       "      <td>[2015-01-24, 2015-06-09]</td>\n",
       "      <td>[1.0, 3.0]</td>\n",
       "      <td>Under 183 days</td>\n",
       "      <td>Multiple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2015-11-07]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>One Off</td>\n",
       "      <td>One Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[2015-06-20]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>One Off</td>\n",
       "      <td>One Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[13, 40]</td>\n",
       "      <td>[2015-03-14, 2016-04-16]</td>\n",
       "      <td>[0.0, 2.0]</td>\n",
       "      <td>Over 183 days</td>\n",
       "      <td>Multiple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event_Count  PersonID Event_IDs               Event_Dates  Series_IDs  \\\n",
       "0            1         1      [11]              [2015-02-15]       [2.0]   \n",
       "1            2         2   [9, 17]  [2015-01-24, 2015-06-09]  [1.0, 3.0]   \n",
       "2            1         3      [30]              [2015-11-07]       [1.0]   \n",
       "3            1         4      [18]              [2015-06-20]       [2.0]   \n",
       "4            2         5  [13, 40]  [2015-03-14, 2016-04-16]  [0.0, 2.0]   \n",
       "\n",
       "  Repeat_Lag_Time Cross_Series_Attend  \n",
       "0         One Off             One Off  \n",
       "1  Under 183 days            Multiple  \n",
       "2         One Off             One Off  \n",
       "3         One Off             One Off  \n",
       "4   Over 183 days            Multiple  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_attendees_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Counts for Single/Repeat Attendees by Type (One Series vs. Multi Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2739.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_repeats_count = float(len(repeat_attendees_df[repeat_attendees_df['Event_Count']>1]))\n",
    "total_repeats_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_attend_single_series = repeat_attendees_df[repeat_attendees_df['Cross_Series_Attend'] > 'Single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1241.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_series = float(len(multi_attend_single_series))\n",
    "single_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_attend_multi_series = repeat_attendees_df[repeat_attendees_df['Cross_Series_Attend'] == 'Multiple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_series = len(multi_attend_multi_series)\n",
    "multi_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_attend = repeat_attendees_df[repeat_attendees_df['Cross_Series_Attend'] == 'One Off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8693"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_attend_count = len(single_attend)\n",
    "single_attend_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11432.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_people = float(len(repeat_attendees_df))\n",
    "total_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24.0% of attendees are repeat. 45.0% of repeat attendees have only attended one series and 55.0% have attended multiple'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}% of attendees are repeat. {}% of repeat attendees have only attended one series \\\n",
    "and {}% have attended multiple'.format(round((single_series+multi_series)/total_people*100), \n",
    "                                       round(single_series/total_repeats_count * 100), \n",
    "                                       round(multi_series/total_repeats_count * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_attend_single_series_counts = multi_attend_single_series.groupby(by='Cross_Series_Attend')['Event_Count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Single - 0.0', 'Single - 1.0', 'Single - 2.0', 'Single - 3.0',\n",
       "       'Single - 4.0'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_attend_single_series_counts.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1241 Repeat Attendees all in One Series, Breakdown is:\n",
      "Series 0: 3.0%\n",
      "Series 1: 24.0%\n",
      "Series 2: 45.0%\n",
      "Series 3: 10.0%\n",
      "Series 4: 18.0%\n"
     ]
    }
   ],
   "source": [
    "print 'For the {} Repeat Attendees all in One Series, Breakdown is:'.format(int(single_series))\n",
    "for idx, val in enumerate(multi_attend_single_series_counts):\n",
    "    print 'Series {}: {}%'.format(idx, round(val/single_series * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New DF Capturing Repeat Attendee Data by Event ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_person_count_df = df.groupby(by='EventID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df = pd.DataFrame.from_dict({'EventID': event_person_count_df.index.values, \n",
    "                                              'Total_Part_Count': event_person_count_df['PersonID'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventID_personID_dict = defaultdict(list)\n",
    "eventID_eventdate_dict = defaultdict(list)\n",
    "eventID_eventname_dict = defaultdict(list)\n",
    "eventID_seriesID_dict = defaultdict(list)\n",
    "eventdate_dict = defaultdict(list)\n",
    "eventname_dict = defaultdict(list)\n",
    "seriesID_dict = defaultdict(list)\n",
    "\n",
    "for num in event_person_count_df.index.values:\n",
    "    eventID_personID_dict[num].append(list(df[df['EventID']==num]['PersonID'].values))\n",
    "    eventID_eventdate_dict[num].append(list(df[df['EventID']==num]['Event_Date'].values))\n",
    "    eventID_eventname_dict[num].append(list(df[df['EventID']==num]['Event_Name'].values))\n",
    "    eventID_seriesID_dict[num].append(list(df[df['EventID']==num]['SeriesID'].values))\n",
    "    \n",
    "    eventdate_dict[num] = eventID_eventdate_dict[num][0][0]\n",
    "    eventname_dict[num] = eventID_eventname_dict[num][0][0]\n",
    "    seriesID_dict[num] = eventID_seriesID_dict[num][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df['Person_IDs'] = events_df['EventID'].map(eventID_personID_dict).apply(lambda x: x[0])\n",
    "events_df['Event_Date'] = events_df['EventID'].map(eventdate_dict).apply(lambda x: np.datetime64(x, 'D'))\n",
    "events_df['Event_Name'] = events_df['EventID'].map(eventname_dict)\n",
    "events_df['Series_ID'] = events_df['EventID'].map(seriesID_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_data_dict = defaultdict(list)\n",
    "for event in events_df['EventID'].values:\n",
    "    repeats_singleseries = 0\n",
    "    repeats_multiseries = 0\n",
    "    single_attend = 0\n",
    "    first_timer = 0\n",
    "    under_six_month_repeat = 0\n",
    "    over_six_month_repeat = 0\n",
    "    first_timer_ids = list()\n",
    "    for person in events_df[events_df['EventID'] == event]['Person_IDs'].values[0]:\n",
    "        att_status = repeat_attendees_df[repeat_attendees_df['PersonID'] == person]['Cross_Series_Attend'].values[0]\n",
    "        lag_status = repeat_attendees_df[repeat_attendees_df['PersonID'] == person]['Repeat_Lag_Time'].values[0]\n",
    "        if att_status == 'Multiple':\n",
    "            repeats_multiseries += 1\n",
    "        elif att_status == 'One Off':\n",
    "            single_attend += 1\n",
    "        else:\n",
    "            repeats_singleseries += 1\n",
    "            \n",
    "        if min(repeat_attendees_df[repeat_attendees_df['PersonID']==person]['Event_Dates'].values[0]) == events_df[\n",
    "            events_df['EventID']==event]['Event_Date'].values[0]:\n",
    "            first_timer += 1\n",
    "            first_timer_ids.append(person)\n",
    "            if lag_status == 'Under 183 days':\n",
    "                under_six_month_repeat += 1\n",
    "            elif lag_status == 'Over 183 days':\n",
    "                over_six_month_repeat += 1\n",
    "            \n",
    "    event_data_dict['repeat_singleseries'].append(repeats_singleseries)\n",
    "    event_data_dict['repeat_multiseries'].append(repeats_multiseries)\n",
    "    event_data_dict['single_attend'].append(single_attend)\n",
    "    event_data_dict['first_timer'].append(first_timer)\n",
    "    event_data_dict['six_mo_repeat'].append(under_six_month_repeat)\n",
    "    event_data_dict['longer_repeat'].append(over_six_month_repeat)\n",
    "    event_data_dict['first_timer_ids'].append(first_timer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df['Repeat_SingleSeries'] = event_data_dict['repeat_singleseries']\n",
    "events_df['Repeat_MultiSeries'] = event_data_dict['repeat_multiseries']\n",
    "events_df['Single_Attend'] = event_data_dict['single_attend']\n",
    "events_df['First_Timers'] = event_data_dict['first_timer']\n",
    "events_df['First_Timer_IDs'] = event_data_dict['first_timer_ids']\n",
    "events_df['Repeat_Under_Six_Mo'] = event_data_dict['six_mo_repeat']\n",
    "events_df['Repeat_Over_Six_Mo'] = event_data_dict['longer_repeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df.sort_values(by='Event_Date', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df['%_Repeat_Under_Six'] = 100 * events_df['Repeat_Under_Six_Mo'] / (events_df['First_Timers'])\n",
    "events_df['%_Repeat_Under_Six'] = events_df['%_Repeat_Under_Six'].apply(lambda x: int(x))\n",
    "\n",
    "events_df['%_Repeat_Over_Six'] = 100 * events_df['Repeat_Over_Six_Mo'] / (events_df['First_Timers'])\n",
    "events_df['%_Repeat_Over_Six'] = events_df['%_Repeat_Over_Six'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "\n",
    "X = events_df['Event_Date'].iloc[0:80].values #include data through June 7th 2017; 6 months ago\n",
    "Y = events_df['%_Repeat_Over_Six'].iloc[0:80].values + events_df['%_Repeat_Under_Six'].iloc[0:80].values\n",
    "Names = events_df['Event_Name'].iloc[0:80].values\n",
    "Series = events_df['Series_ID'].iloc[0:80].values\n",
    "EventID = events_df['EventID'].iloc[0:80].values\n",
    "\n",
    "ax.plot(X,Y);\n",
    "ax.set_title('% of First Timers at Each Event That Have Returned at Any Time', size=20);\n",
    "\n",
    "ax.hlines(y = 50, xmin=events_df['Event_Date'][0], xmax=events_df['Event_Date'][80], color='r');\n",
    "\n",
    "#for x,y,n,s, e in zip(X, Y, Names, Series, EventID):\n",
    "#    ax.annotate(s = '{}, Series {}, Event {}, {}%'.format(n, s, e, y), xy=(x,y), xytext=(x,y), size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Instances with High % of First Timers Returning Ever ( > 50%):\n",
    "\n",
    "#### 2015:\n",
    "* Absolution Run, ID 8, 50%, Winter Series\n",
    "* Cedar Mountain Trail Run, ID 13, 65%, No Series\n",
    "* Ravenna Refresher, ID 31, 53%, Winter Series\n",
    "\n",
    "#### 2016:\n",
    "* Woodland Park Zoom, ID 43, 55%, Summer Series\n",
    "* Wilburton Hilbilly, ID 44, 74%, Summer Series\n",
    "* Sunshine Salutation, ID 48, 76%, Summer Series\n",
    "\n",
    "#### 2017:\n",
    "* None to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "\n",
    "X = events_df['Event_Date'].iloc[0:80].values #include data through June 7th 2017; 6 months ago\n",
    "Y = events_df['%_Repeat_Under_Six'].iloc[0:80].values\n",
    "Names = events_df['Event_Name'].iloc[0:80].values\n",
    "Series = events_df['Series_ID'].iloc[0:80].values\n",
    "EventID = events_df['EventID'].iloc[0:80].values\n",
    "\n",
    "ax.plot(X,Y);\n",
    "ax.set_title('% of First Timers at Each Event That Return Within 6 Months', size=20);\n",
    "\n",
    "ax.hlines(y = 30, xmin=events_df['Event_Date'][0], xmax=events_df['Event_Date'][80], color='r');\n",
    "\n",
    "#for x,y,n,s, e in zip(X, Y, Names, Series, EventID):\n",
    "#    ax.annotate(s = '{}, {}, {}, {}%'.format(n, s, e, y), xy=(x,y), xytext=(x,y), size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Instances with High % of First Timers Returning in Next 6 Months ( > 30%):\n",
    "\n",
    "#### 2015:\n",
    "* Absolution Run, ID 8, 39%, Winter Series\n",
    "* Cedar Mountain Trail Run, ID 13, 45%, No Series\n",
    "* Ravenna Run the Ravine, ID 17, 34%, Summer Series\n",
    "* Summer Eddy, ID 23, 36%, Summer Series\n",
    "* Carkeek Cooler, ID 30, 39%, Winter Series\n",
    "* Ravenna Refresher, ID 31, 42%, Winter Series\n",
    "\n",
    "#### 2016:\n",
    "* Woodland Park Zoom, ID 43, 45%, Summer Series\n",
    "* Wilburton Hilbilly, ID 44, 58%, Summer Series\n",
    "* Sunshine Salutation, ID 48, 64%, Summer Series\n",
    "* Ravenna Refresher, ID 60, 40%, Winter Series\n",
    "\n",
    "#### 2017:\n",
    "* Woodland Park Zoom, ID 73, 33%, Summer Series\n",
    "* Wilburton Hilbilly, ID 75, 35%, Summer Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(events_df['First_Timers'].iloc[0:80].values) / float(sum(events_df['Total_Part_Count'].iloc[0:80].values)) * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if repeat the above plot but normalize for number of first timers relative to size of event:\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "\n",
    "X = events_df['Event_Date'].iloc[0:80].values #include data through June 7th 2017; 6 months ago\n",
    "Y = events_df['%_Repeat_Under_Six'].iloc[0:80].values * events_df['First_Timers'].iloc[0:80].values / events_df['Total_Part_Count'].iloc[0:80].values\n",
    "Names = events_df['Event_Name'].iloc[0:80].values\n",
    "Series = events_df['Series_ID'].iloc[0:80].values\n",
    "EventID = events_df['EventID'].iloc[0:80].values\n",
    "\n",
    "ax.plot(X,Y);\n",
    "ax.set_title('% of First Timers at Each Event That Return Within 6 Months', size=20);\n",
    "\n",
    "ax.hlines(y = 20, xmin=events_df['Event_Date'][0], xmax=events_df['Event_Date'][80], color='r');\n",
    "\n",
    "#for x,y,n,s, e in zip(X, Y, Names, Series, EventID):\n",
    "#    ax.annotate(s = '{}, {}, {}, {}%'.format(n, s, e, y), xy=(x,y), xytext=(x,y), size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Instances with High % of First Timers Returning in Next 6 Months When Normalized for Number of First Timers at Event ( > 20%):\n",
    "\n",
    "#### 2015:\n",
    "* Absolution Run, ID 8, 38%, Winter Series\n",
    "* Interlaken Icicle Dash, ID 9, 23%, Winter Series\n",
    "* Cedar Mountain Trail Run, ID 13, 25%, No Series\n",
    "* Ravenna Run the Ravine, ID 17, 24%, Summer Series\n",
    "* Carkeek Cooler, ID 30, 27%, Winter Series\n",
    "* Ravenna Refresher, ID 31, 23%, Winter Series\n",
    "\n",
    "Drops Out: Summer Eddy, ID 23, Summer Series\n",
    "\n",
    "#### 2016:\n",
    "* Sunshine Salutation, ID 48, 22%, Summer Series\n",
    "* Ravenna Refresher, ID 60, 21%, Winter Series\n",
    "\n",
    "Drops Out: Woodland Park Zoom, ID 43, Summer Series; Wilburton Hillbilly, ID 44, Summer Series\n",
    "\n",
    "#### 2017:\n",
    "* None meet 20% threshold\n",
    "\n",
    "Drops Out: Woodland Park Zoom, ID 73, Summer Series; Wilburton Hilbilly, ID 75, Summer Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,12))\n",
    "\n",
    "X = events_df['Event_Date'].iloc[0:80].values #include data through June 7th 2017; 6 months ago\n",
    "Y = events_df['%_Repeat_Over_Six'].iloc[0:80].values\n",
    "Names = events_df['Event_Name'].iloc[0:80].values\n",
    "Series = events_df['Series_ID'].iloc[0:80].values\n",
    "\n",
    "ax.plot(X,Y);\n",
    "ax.set_title('% of First Timers at Each Event That Return After Over 6 Months', size=20);\n",
    "\n",
    "#ax.hlines(y = 30, xmin=events_df['Event_Date'][0], xmax=events_df['Event_Date'][80], color='r')\n",
    "\n",
    "for x,y,n,s in zip(X, Y, Names, Series):\n",
    "    ax.annotate(s = '{}, {}, {}%'.format(n, s, y), xy=(x,y), xytext=(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at an Individual Event with High Rate of Return of First Timers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[events_df['EventID']==48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_to_nan(values):\n",
    "    \"\"\"Replace every 0 with 'nan' and return a copy.\"\"\"\n",
    "    return [np.nan if x==0 else x for x in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_event_future_repeats(event_id):\n",
    "    '''Create dataframe for counts of when first timers at a given event have their first repeat attendance, based on \n",
    "    perspective of event with provided event_id'''\n",
    "    idx = (events_df[events_df['EventID']==event_id].index.values[0]) + 1\n",
    "    event_person_list = events_df[events_df['EventID']==event_id]['First_Timer_IDs'].values[0]\n",
    "    future_events_df = events_df[['Event_Name', 'EventID', 'Event_Date', 'Series_ID']].iloc[idx:]\n",
    "    already_repeated_list = list()\n",
    "    event_future_repeats_list = list()\n",
    "    \n",
    "    for event in future_events_df['EventID'].values:\n",
    "        repeat_att = 0\n",
    "        for person in events_df[events_df['EventID']==event]['Person_IDs'].values[0]:\n",
    "            if person in event_person_list and person not in already_repeated_list:\n",
    "                repeat_att += 1\n",
    "                already_repeated_list.append(person)\n",
    "        event_future_repeats_list.append(repeat_att)\n",
    "    \n",
    "    future_events_df['Repeats'] = zero_to_nan(event_future_repeats_list)\n",
    "    \n",
    "    return future_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_single_event_future_repeats(event_id_list):\n",
    "    \n",
    "    subplot_size = len(event_id_list)\n",
    "    fig, axes = plt.subplots(subplot_size, 1, figsize=(20,30))\n",
    "    \n",
    "    for ax, event_id in zip(axes.flatten(), event_id_list):\n",
    "        event_futurerepeats_df = single_event_future_repeats(event_id)\n",
    "        X = event_futurerepeats_df['Event_Date'].values\n",
    "        Y = event_futurerepeats_df['Repeats'].values\n",
    "        ymax = np.nanmax(Y) + np.nanmax(Y) / 2\n",
    "        ymin = np.nanmin(Y) / 10\n",
    "        Names = event_futurerepeats_df['Event_Name'].values\n",
    "        Series = event_futurerepeats_df['Series_ID'].values\n",
    "        \n",
    "        ax.scatter(X,Y);\n",
    "        ax.set_title('Spread of First Repeat for First Timers at Event #{}, {}'.format(\n",
    "            event_id,events_df[events_df['EventID']==event_id]['Event_Name'].values[0]), size=13);\n",
    "        ax.set_xlabel('Event Date')\n",
    "        ax.set_ylabel('Number of Attendees')\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "        \n",
    "        for x,y,n,s in zip(X, Y, Names, Series):\n",
    "            ax.annotate(s = '{}'.format(n), xy=(x,y), xytext=(x,y), verticalalignment='bottom', \n",
    "                       horizontalalignment = 'left', rotation = 60)\n",
    "            \n",
    "        textstr = 'Total Event Size: {} \\n First Timers: {}'.format(\n",
    "            events_df[events_df['EventID']==event_id]['Total_Part_Count'].values[0], \n",
    "            events_df[events_df['EventID']==event_id]['First_Timers'].values[0], \n",
    "            events_df[events_df['EventID']==event_id])\n",
    "        \n",
    "        #these are matplotlib.path.Patch properties\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        \n",
    "        #place a text box in the upper left in axes coords\n",
    "        ax.text(0.85, 0.96, textstr, transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_event_future_repeats([43, 44, 48, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
