{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up psql connection in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname='mergeoruns101717', host='localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of All Tables in MergeoRuns DB\n",
    "### Identify columns of data to pull into my dataset\n",
    "\n",
    "### Tables with Columns I want:\n",
    "\n",
    "* ##### Table: DistanceSorts\n",
    "    * Pull \"Miles\" to associate with \"Distance\" of each race (\"Distance\" already in PersonEvents)\n",
    "* ##### Table: EventTypes\n",
    "    * Pull type name to add against each event ID\n",
    "* ##### Table: Events\n",
    "    * Pull Event Date, Mergeo Event, Event Type ID\n",
    "* ##### Table: PersonEvents\n",
    "    * Use as starting point for my dataset.  Keep most columns; exclude: Bib, Start, Finish (S/F covered by Time), Phone #, Emergency Contact Phone #, Email, Tshirt Size, Hoodie Size, Notes (blank column)\n",
    "* ##### Table: Persons\n",
    "    * Pull Gender\n",
    "* ##### Table: SS_TeamPeople\n",
    "    * Pull pre-reg info for a given personID, eventID to put in master dataset; also pull HowHeard column (missing lots of data there though...)\n",
    "* ##### Table: Series\n",
    "    * Pull Series name to associate with Series ID\n",
    "* ##### Table: SeriesEvents\n",
    "    * Pull Series ID to use for indication of whether given event ID is part of a series or not, and if yes which series\n",
    "\n",
    "\n",
    "### Tables I won't use (at least for now):\n",
    "\n",
    "* ##### Table: Cities\n",
    "    * Pull none; duplicate to data already in PersonEvents table\n",
    "* ##### Table: EventDistances\n",
    "    * Pull none; duplicate to data already in PersonEvents table\n",
    "* ##### Table: Import Database\n",
    "    * Pull none, all data represented in other tables I'll pull from (DB manager uses this for his import processing to Access)\n",
    "* ##### Table: SS_Class, SS_Division, SS_Exclude, SS_Hours, SS_TeamReport, SS_Teams\n",
    "    * Exclude for now; not doing any specific work with scores, sub-categories within a race type at this time.\n",
    "* ##### Table: SameName\n",
    "    * pull none; I'm using PersonID, EventID only, not names, so irrelevant for my purposes.\n",
    "* ##### Tables: SeriesCategories, SeriesPoints, SeriesRules\n",
    "    * Exclude for now; not doing any specific work with scores / points or sub-categories within a race type at this time.\n",
    "* ##### Tables: tmpAttendanceCrosstab, tmpHighScores, tmpHighScoresCrosstab, tmpPersonRanks, tmpSeriesEventAttendance, tmpSeriesPoints, tmpSeriesPointsAvg, tmpSeriesRank, tmpSeriesTopXPoints\n",
    "    * All of these tables are calculations the DB manager did to look at attendance across events, scores, rankings, and to calculate series scores/ranks.  At this point I will exclude all of these.  I will do my own EDA for attendance, and if I do use people's rankings in given events that will be done later (not part of base model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test run of small subset of data with only the columns I want from PersonEvents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_query = '''\n",
    "        SELECT \"PersonID\", \"EventID\", \"Distance\", \"Time\", \"Age\", \"Registration time\", \"Total fee\", \"Payment method\",\n",
    "        \"Street Address\", \"City\", \"State/Province\", \"Emergency contact name\", \"Zip Code\", \"Country\", \"Contact\", \n",
    "        \"Tshirt\", \"Hoodie\"\n",
    "        FROM \"PersonEvents\"\n",
    "        LIMIT 10;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(tst_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_output = cur.fetchmany(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_output, columns=[\"PersonID\", \"EventID\", \"Distance\", \"Time\", \"Age\", \"Registration time\", \"Total fee\", \"Payment method\",\n",
    "        \"Street Address\", \"City\", \"State/Province\", \"Emergency contact name\", \"Zip Code\", \"Country\", \"Contact\", \n",
    "        \"Tshirt\", \"Hoodie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at joins to collect data from all tables that I want and include in combined table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        WITH master_temp\n",
    "        AS (SELECT pe.\"PersonID\", pe.\"EventID\", pe.\"Distance\", pe.\"Time\", pe.\"Age\", pe.\"Registration time\", \n",
    "        pe.\"Total fee\", pe.\"Payment method\", pe.\"Street Address\", pe.\"City\", pe.\"State/Province\", \n",
    "        pe.\"Emergency contact name\", pe.\"Zip Code\", pe.\"Country\", pe.\"Contact\", pe.\"Tshirt\", pe.\"Hoodie\", \n",
    "        e.\"Event_Date\", e.\"MergeoEvent\", e.\"EventTypeID\", se.\"SeriesID\"\n",
    "        FROM \"PersonEvents\" pe\n",
    "        LEFT JOIN \"Events\" e ON pe.\"EventID\" = e.\"EventID\"\n",
    "        LEFT JOIN \"SeriesEvents\" se ON pe.\"EventID\" = se.\"EventID\") \n",
    "        SELECT mt.\"PersonID\", mt.\"EventID\", mt.\"Age\", p.\"Gender\", mt.\"Distance\", ds.\"Miles\", mt.\"Time\", mt.\"Total fee\", \n",
    "        sstp.\"Prereg\", mt.\"Registration time\", mt.\"Payment method\", mt.\"Street Address\", mt.\"City\", mt.\"State/Province\",\n",
    "        mt.\"Zip Code\", mt.\"Country\", mt.\"Emergency contact name\", mt.\"Contact\", mt.\"Tshirt\", mt.\"Hoodie\", \n",
    "        mt.\"Event_Date\", mt.\"MergeoEvent\", mt.\"EventTypeID\", et.\"EventType\", mt.\"SeriesID\", s.\"Series\", sstp.\"HowHeard\" \n",
    "        FROM master_temp mt\n",
    "        LEFT JOIN \"DistanceSorts\" ds ON LOWER(mt.\"Distance\") = LOWER(ds.\"Distance\")\n",
    "        LEFT JOIN \"EventTypes\" et ON mt.\"EventTypeID\" = et.\"EventTypeID\"\n",
    "        LEFT JOIN \"Persons\" p ON p.\"PersonID\" = mt.\"PersonID\"\n",
    "        LEFT JOIN \"SS_TeamPeople\" sstp ON mt.\"PersonID\" = sstp.\"PersonID\" AND mt.\"EventID\" = sstp.\"EventID\"\n",
    "        LEFT JOIN \"Series\" s ON mt.\"SeriesID\" = s.\"SeriesID\"\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(query_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Pandas DF from query results - this will be the base dataset that I'll clean and do feature engineering on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_columns = [\"PersonID\", \"EventID\", \"Age\", \"Gender\", \"Distance\", \"Miles\", \"Time\", \"Total fee\", \"SS_Prereg\", \n",
    "                \"Registration time\", \"Payment method\", \"Street Address\", \"City\", \"State/Province\", \"Zip Code\", \n",
    "                \"Country\", \"Emergency contact name\", \"Contact\", \"Tshirt\", \"Hoodie\", \"Event_Date\", \"MergeoEvent\",\n",
    "                \"EventTypeID\", \"EventType\", \"SeriesID\", \"Series\", \"HowHeard\"]\n",
    "\n",
    "base_dataset = pd.DataFrame(query_results, columns = data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#base_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16989 entries, 0 to 16988\n",
      "Data columns (total 27 columns):\n",
      "PersonID                  16989 non-null float64\n",
      "EventID                   16989 non-null int64\n",
      "Age                       16612 non-null object\n",
      "Gender                    16972 non-null object\n",
      "Distance                  14699 non-null object\n",
      "Miles                     14296 non-null float64\n",
      "Time                      14691 non-null object\n",
      "Total fee                 12765 non-null object\n",
      "SS_Prereg                 813 non-null object\n",
      "Registration time         11743 non-null datetime64[ns]\n",
      "Payment method            13491 non-null object\n",
      "Street Address            14073 non-null object\n",
      "City                      15243 non-null object\n",
      "State/Province            16098 non-null object\n",
      "Zip Code                  14989 non-null object\n",
      "Country                   15807 non-null object\n",
      "Emergency contact name    12570 non-null object\n",
      "Contact                   16434 non-null object\n",
      "Tshirt                    4965 non-null object\n",
      "Hoodie                    4696 non-null object\n",
      "Event_Date                16989 non-null datetime64[ns]\n",
      "MergeoEvent               16989 non-null bool\n",
      "EventTypeID               16989 non-null int64\n",
      "EventType                 16989 non-null object\n",
      "SeriesID                  9863 non-null float64\n",
      "Series                    9863 non-null object\n",
      "HowHeard                  99 non-null object\n",
      "dtypes: bool(1), datetime64[ns](2), float64(3), int64(2), object(19)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "base_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address person/event entries with missing ages; many of these people have age entries for other races they attended - if they do, will populate with that age, else will use mean age of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persons_no_age = base_dataset[pd.isnull(base_dataset['Age'])]['PersonID'].values\n",
    "\n",
    "persIDs_ages = zip(list(base_dataset['PersonID'].values), list(base_dataset['Age'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "D_age = defaultdict(list)\n",
    "\n",
    "for persID, age in persIDs_ages:\n",
    "    if pd.notnull(age):\n",
    "        D_age[persID].append(int(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D2_age = defaultdict(list)\n",
    "\n",
    "for person in persons_no_age:\n",
    "    ages_list = D_age.get(person)\n",
    "    if ages_list is None:\n",
    "        D2_age[person] = np.NaN\n",
    "    elif len(ages_list) == 0:\n",
    "        D2_age[person] = np.NaN\n",
    "    else:\n",
    "        D2_age[person] = int(np.round(np.mean(ages_list), decimals=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Age2'] = base_dataset[['PersonID', 'Age']].apply(lambda row: int(row[1]) if pd.notnull(row[1]) else D2_age[row[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Age2'].fillna(value=int(base_dataset['Age2'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset = base_dataset.drop('Age', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16989 entries, 0 to 16988\n",
      "Data columns (total 27 columns):\n",
      "PersonID                  16989 non-null float64\n",
      "EventID                   16989 non-null int64\n",
      "Gender                    16972 non-null object\n",
      "Distance                  14699 non-null object\n",
      "Miles                     14296 non-null float64\n",
      "Time                      14691 non-null object\n",
      "Total fee                 12765 non-null object\n",
      "SS_Prereg                 813 non-null object\n",
      "Registration time         11743 non-null datetime64[ns]\n",
      "Payment method            13491 non-null object\n",
      "Street Address            14073 non-null object\n",
      "City                      15243 non-null object\n",
      "State/Province            16098 non-null object\n",
      "Zip Code                  14989 non-null object\n",
      "Country                   15807 non-null object\n",
      "Emergency contact name    12570 non-null object\n",
      "Contact                   16434 non-null object\n",
      "Tshirt                    4965 non-null object\n",
      "Hoodie                    4696 non-null object\n",
      "Event_Date                16989 non-null datetime64[ns]\n",
      "MergeoEvent               16989 non-null bool\n",
      "EventTypeID               16989 non-null int64\n",
      "EventType                 16989 non-null object\n",
      "SeriesID                  9863 non-null float64\n",
      "Series                    9863 non-null object\n",
      "HowHeard                  99 non-null object\n",
      "Age2                      16989 non-null float64\n",
      "dtypes: bool(1), datetime64[ns](2), float64(4), int64(2), object(18)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "base_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address person/event entries with missing genders if these people have gender entries for other races they attended - if they do, will populate with that gender; for remaining will add third value for other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persons_no_gender = base_dataset[pd.isnull(base_dataset['Gender'])]['PersonID'].values\n",
    "\n",
    "persIDs_genders = zip(list(base_dataset['PersonID'].values), list(base_dataset['Gender'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#persons_no_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_gen = defaultdict(list)\n",
    "\n",
    "for persID, gender in persIDs_genders:\n",
    "    if pd.notnull(gender):\n",
    "        D_gen[persID].append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D2_gen = defaultdict(list)\n",
    "\n",
    "for person in persons_no_gender:\n",
    "    gen = D_gen.get(person)\n",
    "    if gen is None:\n",
    "        D2_gen[person] = None\n",
    "    else:\n",
    "        D2_gen[person] = gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#D2_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In all cases will replace with third value of 'other' based on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Gender'].fillna(value='Other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing distances with 'Variable-SS' indicating this is a street scramble and distances vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Distance'].fillna(value='Variable-SS', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address null values in Miles column - most of these can be populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6. ,   3. ,   4.4,  13. ,   5. ,   7.5,   8. ,  26. ,  30. ,\n",
       "         nan,  20. ,  10. ,   4. ,   2.5,   4.2,  50. ,  18. ,  19.5,\n",
       "         0. ,  63. ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset['Miles'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1/2 Marathon', 'Variable-SS', 'Half Marathon early start',\n",
       "       '5k early start', '5 Mile late start', '10k early start',\n",
       "       'Half Marathon late start'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset[pd.isnull(base_dataset['Miles'])]['Distance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_dict = {'1/2 Marathon':13., 'Half Marathon early start':13., '5k early start':3., '5 Mile late start': 5., \n",
    "            '10k early start':6., 'Half Marathon late start':13., 'Variable-SS':np.NaN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Miles2'] = base_dataset[['Distance', 'Miles']].apply(lambda row: row[1] if pd.notnull(row[1]) \n",
    "                                                               else dist_dict[row[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset = base_dataset.drop('Miles', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now, replaced NANs for times for all street scramble events with 90 minutes; some of these are 3 hr or 2 hr but I don't have the granularity to see that yet.  Follow up question for Dan...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Time2'] = base_dataset[['EventID', 'Time']].apply(lambda row: '1:30:00.0' if row[0] > 999 else row[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[270, 4115, 4824, 5308, 5879, 6396, 6515, 6700, 7314, 10183, 10186]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(base_dataset[pd.isnull(base_dataset['Time2'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop non-street scramble records that are missing times (only 11 of them, most from EventID 14, a couple from 37)\n",
    "#Check with Dan on these\n",
    "base_dataset.drop(labels=[270, 4115, 4824, 5308, 5879, 6396, 6515, 6700, 7314, 10183, 10186], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset = base_dataset.drop('Time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert Total fee column from string to float, setting errors to NaNs\n",
    "base_dataset['Total fee'] = pd.to_numeric(base_dataset['Total fee'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fill na's in Total fee column with average cost\n",
    "base_dataset['Total fee'].fillna(value=round(base_dataset['Total fee'].mean(),2), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Preregistered'] = base_dataset[['SS_Prereg', 'Registration time']].apply(lambda row: 1 if ((row[0]) or (pd.notnull(row[1]))) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset.drop(['SS_Prereg', 'Registration time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['has_emerg_contact'] = base_dataset[['Emergency contact name']].apply(lambda row: 1 if pd.notnull(row[0])\n",
    "                                                                                  else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset.drop('Emergency contact name', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Tshirt'].fillna(value='N', inplace=True)\n",
    "base_dataset['Hoodie'].fillna(value='N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriesID\n",
       "1.0    1993\n",
       "2.0    2418\n",
       "3.0     698\n",
       "4.0    1701\n",
       "5.0    2261\n",
       "6.0     792\n",
       "Name: SeriesID, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset.groupby('SeriesID')['SeriesID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align winter series from 2015/2016 and 2016/2017 under ID 1\n",
    "base_dataset['SeriesID'] = base_dataset[['SeriesID']].apply(\n",
    "                                lambda row: 1. if row[0] == 4. else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriesID\n",
       "1.0    3694\n",
       "2.0    2418\n",
       "3.0     698\n",
       "5.0    2261\n",
       "6.0     792\n",
       "Name: SeriesID, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset.groupby('SeriesID')['SeriesID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align half marathon series from 206 and 2017 under ID 2\n",
    "base_dataset['SeriesID'] = base_dataset[['SeriesID']].apply(\n",
    "                                lambda row: 2. if row[0] == 5. else row[0], axis=1)\n",
    "#align trail to grill series from 2016 and 2017 under ID 3\n",
    "base_dataset['SeriesID'] = base_dataset[['SeriesID']].apply(\n",
    "                                lambda row: 3. if row[0] == 6. else row[0], axis=1)\n",
    "#assign a series ID to Street Scrambles, set under ID 4\n",
    "base_dataset['SeriesID'] = base_dataset[[\n",
    "                                'EventType', 'SeriesID']].apply(\n",
    "                                lambda row: 4. if row[0] == 'Street Scramble'\n",
    "                                else row[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriesID\n",
       "1.0    3694\n",
       "2.0    4679\n",
       "3.0    1490\n",
       "4.0    2287\n",
       "Name: SeriesID, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset.groupby('SeriesID')['SeriesID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['SeriesID'].fillna(value=0., inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset['SeriesID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['HasSeries'] = base_dataset[['SeriesID']].apply(lambda row: 'Y' if pd.notnull(row[0]) else 'N', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset.drop('Series', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset.drop('HowHeard', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Miles2'].fillna(value=round(base_dataset['Miles2'].mean(), 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Payment method'] = base_dataset[['Payment method']].apply(lambda row: 'cash' if (\n",
    "                                                            row[0] == 'Cash' or \n",
    "                                                            row[0] == 'cash/comp')\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Payment method'] = base_dataset[['Payment method']].apply(lambda row: 'check' if (\n",
    "                                                            row[0] == 'Check')\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Payment method'] = base_dataset[['Payment method']].apply(lambda row: 'credit' if (\n",
    "                                                            row[0] == 'Authorize' or\n",
    "                                                            row[0] == 'CC' or\n",
    "                                                            row[0] == 'cc' or\n",
    "                                                            row[0] == '$261 CC, $30 cash')\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Payment method'] = base_dataset[['Payment method']].apply(lambda row: 'paypal' if (\n",
    "                                                            row[0] == 'PayPal' or \n",
    "                                                            row[0] == 'PayPal pending')\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Payment method'] = base_dataset[['Payment method']].apply(lambda row: 'comp' if (\n",
    "                                                            row[0] == 'Comp')\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Payment method'] = base_dataset[['Payment method']].apply(lambda row: 'other' if (\n",
    "                                                            row[0] != 'cash' and row[0] != 'check' and row[0] != 'comp'\n",
    "                                                            and row[0] != 'credit' and row[0] != 'paypal' and row[0] != None)\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['has_pay_method'] = base_dataset[['Payment method']].apply(lambda row: 'N' if row[0] == None else 'Y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset.groupby(by='Payment method')['PersonID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset['Contact'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Contact'] = base_dataset[['Contact']].apply(lambda row: 'No' if (\n",
    "                                                            row[0] == 'no' or row[0] == 'NO')\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Contact'] = base_dataset[['Contact']].apply(lambda row: 'No Response' if (\n",
    "                                                            row[0] == '-1' or row[0] == '0' or row[0] == None)\n",
    "                                                        else row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset.groupby('Contact')['Contact'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cur.execute(query)\n",
    "#for record in cur:\n",
    "#    print \"{}: user {} logged in via {}\".format(record[1], record[0], record[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cur.close() # This is optional\n",
    "#conn.close() # Closing the connection also closes all cursors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
